@article{YAN2017,
title = "Improving Performance of Breast Cancer Risk Prediction by Incorporating Optical Density Image Feature Analysis: An Assessment",
journal = "Academic Radiology",
year = "2017",
issn = "1076-6332",
doi = "https://doi.org/10.1016/j.acra.2017.08.007",
url = "http://www.sciencedirect.com/science/article/pii/S1076633217303641",
author = "Shiju Yan and Yunzhi Wang and Faranak Aghaei and Yuchen Qiu and Bin Zheng",
keywords = "Breast cancer, computer-aided detection (CAD), risk stratification, image conversion, feature analysis",
abstract = "Rationale and Objectives
The purpose of this study is to improve accuracy of near-term breast cancer risk prediction by applying a new mammographic image conversion method combined with a two-stage artificial neural network (ANN)-based classification scheme.
Materials and Methods
The dataset included 168 negative mammography screening cases. In developing and testing our new risk model, we first converted the original grayscale value (GV)-based mammographic images into optical density (OD)-based images. For each case, our computer-aided scheme then computed two types of image features representing bilateral asymmetry and the maximum of the image features computed from GV and OD images, respectively. A two-stage classification scheme consisting of three ANNs was developed. The first stage included two ANNs trained using features computed separately from GV and OD images of 138 cases. The second stage included another ANN to fuse the prediction scores produced by two ANNs in the first stage. The risk prediction performance was tested using the rest 30 cases.
Results
With the two-stage classification scheme, the computed area under the receiver operating characteristic curve (AUC) was  0.816 ± 0.071, which was significantly higher than the AUC values of 0.669 ± 0.099 and 0.646 ± 0.099 achieved using two ANNs trained using GV features and OD features, respectively (P < .05).
Conclusion
This study demonstrated that applying an OD image conversion method can acquire new complimentary information to those acquired from the original images. As a result, fusion image features computed from these two types of images yielded significantly higher performance in near-term breast cancer risk prediction."
}